{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Disclaimer: We use some advanced packages here without detailed explanation. You can use these, but we do not provide any support.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install them, you can uncomment the following lines:\n",
    "# (%pip will call pip from the currently active python environment)\n",
    "\n",
    "# Note: Some of these packages are still not compatible with Python 3.12 yet\n",
    "# %pip install sweetviz\n",
    "# %pip install ydata_profiling\n",
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "#import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility \n",
    "\n",
    "A best practice in data analytics projects is to work with *seeds* to ensure the reproducability of results. \n",
    "This is especially important in the Analytics Cup, since the rules require you to write a self-contained\n",
    "script that produces reproducable results. \n",
    "\n",
    "To achieve this, we can set seeds for all used random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Business Understanding\n",
    "\n",
    "Serves to assess use cases, feasibility, requirements, and\n",
    "risks of the endeavored data driven project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Data Understanding\n",
    "\n",
    "Assess the data quality and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/gcpryyxs74146gl1yfg2msyw0000gn/T/ipykernel_22745/1456728697.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.read_csv(\"reviews.csv\")\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "diet = pd.read_csv(\"diet.csv\")\n",
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "requests = pd.read_csv(\"requests.csv\")\n",
    "reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the data and its attributes \\\n",
    "check if columns are properly named \\\n",
    "general overview over data, check for missing values, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Diet</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000120E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000014D</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000015A</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000016E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000027E</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AuthorId        Diet  Age\n",
       "0  10000120E  Vegetarian   46\n",
       "1   1000014D       Vegan   18\n",
       "2   1000015A  Vegetarian   58\n",
       "3   1000016E  Vegetarian   32\n",
       "4   1000027E       Vegan   61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271907 entries, 0 to 271906\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   AuthorId  271907 non-null  object\n",
      " 1   Diet      271906 non-null  object\n",
      " 2   Age       271907 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "diet.info()\n",
    "# To do: ver qual o valor nulo que tem na coluna Diet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Name</th>\n",
       "      <th>CookTime</th>\n",
       "      <th>PrepTime</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>RecipeIngredientQuantities</th>\n",
       "      <th>RecipeIngredientParts</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>RecipeYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Bow Ties With Broccoli Pesto</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...</td>\n",
       "      <td>c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Cashew-chutney Rice</td>\n",
       "      <td>3600</td>\n",
       "      <td>600</td>\n",
       "      <td>Other</td>\n",
       "      <td>c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...</td>\n",
       "      <td>c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Copycat Taco Bell Nacho Fries BellGrande</td>\n",
       "      <td>3600</td>\n",
       "      <td>2700</td>\n",
       "      <td>Other</td>\n",
       "      <td>c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...</td>\n",
       "      <td>c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Slow Cooker Jalapeno Cheddar Cheese Soup</td>\n",
       "      <td>18000</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...</td>\n",
       "      <td>c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Cool &amp; Crisp Citrus Chiffon Pie</td>\n",
       "      <td>3600</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...</td>\n",
       "      <td>c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId                                      Name  CookTime  PrepTime  \\\n",
       "0     73440              Bow Ties With Broccoli Pesto         0      1800   \n",
       "1    365718                       Cashew-chutney Rice      3600       600   \n",
       "2    141757  Copycat Taco Bell Nacho Fries BellGrande      3600      2700   \n",
       "3    280351  Slow Cooker Jalapeno Cheddar Cheese Soup     18000      1800   \n",
       "4    180505           Cool & Crisp Citrus Chiffon Pie      3600      1800   \n",
       "\n",
       "  RecipeCategory                         RecipeIngredientQuantities  \\\n",
       "0          Other  c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...   \n",
       "1          Other  c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...   \n",
       "2          Other  c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...   \n",
       "3          Other  c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...   \n",
       "4          Other  c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...   \n",
       "\n",
       "                               RecipeIngredientParts  Calories  FatContent  \\\n",
       "0  c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...     241.3        10.1   \n",
       "1  c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...     370.8        17.5   \n",
       "2  c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...     377.6        20.9   \n",
       "3  c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...     282.8        16.5   \n",
       "4  c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...     257.5         8.6   \n",
       "\n",
       "   SaturatedFatContent  CholesterolContent  SodiumContent  \\\n",
       "0                  1.2                 0.0           13.1   \n",
       "1                  7.2                22.9          553.3   \n",
       "2                 10.5                45.7         1501.8   \n",
       "3                 10.3                50.5          630.2   \n",
       "4                  2.4               110.7          160.9   \n",
       "\n",
       "   CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n",
       "0                 31.8           2.3           1.4             6.7   \n",
       "1                 44.3           1.6           2.2             9.4   \n",
       "2                 36.6           3.8           6.1            12.9   \n",
       "3                 22.8           2.3           2.7            11.7   \n",
       "4                 39.8           0.4          30.2             6.3   \n",
       "\n",
       "   RecipeServings RecipeYield  \n",
       "0             9.0         NaN  \n",
       "1             8.0         NaN  \n",
       "2             8.0         NaN  \n",
       "3             6.0         NaN  \n",
       "4             6.0         NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipes table pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "# rename columns (?)\n",
    "recipes.rename(columns={\n",
    "    'RecipeCategory': 'Category',\n",
    "    'RecipeIngredientQuantities': 'IngredientQuantities',\n",
    "    'RecipeIngredientParts': 'IngredientParts'\n",
    "}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change types of column\n",
    "def refactorIngredients(ingredients):\n",
    "    if ingredients == \"character(0)\":\n",
    "        return []\n",
    "    ingredients = ingredients.replace(\"\\\\\", '').replace(\"\\\"\", '').replace('c(','').replace(')', '')\n",
    "    ingredients = ingredients.split(\",\")\n",
    "    return ingredients\n",
    "\n",
    "recipes[\"Category\"] = recipes[\"Category\"].astype(\"category\")\n",
    "recipes[\"IngredientQuantities\"] = recipes[\"IngredientQuantities\"].apply(lambda x: refactorIngredients(x))\n",
    "recipes[\"IngredientParts\"] = recipes[\"IngredientParts\"].apply(lambda x: refactorIngredients(x))\n",
    "\n",
    "#recipes.astype({'Name': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75604 entries, 0 to 75603\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   RecipeId              75604 non-null  int64   \n",
      " 1   Name                  75604 non-null  object  \n",
      " 2   CookTime              75604 non-null  int64   \n",
      " 3   PrepTime              75604 non-null  int64   \n",
      " 4   Category              75604 non-null  category\n",
      " 5   IngredientQuantities  75604 non-null  object  \n",
      " 6   IngredientParts       75604 non-null  object  \n",
      " 7   Calories              75604 non-null  float64 \n",
      " 8   FatContent            75604 non-null  float64 \n",
      " 9   SaturatedFatContent   75604 non-null  float64 \n",
      " 10  CholesterolContent    75604 non-null  float64 \n",
      " 11  SodiumContent         75604 non-null  float64 \n",
      " 12  CarbohydrateContent   75604 non-null  float64 \n",
      " 13  FiberContent          75604 non-null  float64 \n",
      " 14  SugarContent          75604 non-null  float64 \n",
      " 15  ProteinContent        75604 non-null  float64 \n",
      " 16  RecipeServings        48891 non-null  float64 \n",
      " 17  RecipeYield           25309 non-null  object  \n",
      "dtypes: category(1), float64(10), int64(3), object(4)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "recipes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecipeServingsValue  RecipeYieldValue\n",
      "0                    0                   12854\n",
      "                     1                   13859\n",
      "1                    0                   37441\n",
      "                     1                   11450\n",
      "Name: RecipeId, dtype: int64\n",
      "IngredientPartsEmpty  IngredientQuantitiesEmpty\n",
      "False                 False                        75204\n",
      "                      True                            96\n",
      "True                  False                          299\n",
      "                      True                             5\n",
      "Name: RecipeId, dtype: int64\n",
      "number of corrupted ingredient list 56479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>IngredientParts</th>\n",
       "      <th>IngredientQuantities</th>\n",
       "      <th>IngredientQuantitiesLen</th>\n",
       "      <th>IngredientPartsLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>[celery,  onion,  butter,  chicken broth,  lon...</td>\n",
       "      <td>[1,  3/4,  6,  5,  2,  1,  2]</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>[Copycat Taco Bell Seasoned Beef,  yellow onio...</td>\n",
       "      <td>[3,  1/2,  1,  1,  3,  2,  1,  2 1/2,  2,  1, ...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>[unsalted butter,  yellow onion,  carrots,  ga...</td>\n",
       "      <td>[2,  1,  2,  2,  1,  1,  1/8,  1/4,  1,  4,  3...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>[unflavored gelatin,  water,  sugar,  lemon,  ...</td>\n",
       "      <td>[1,  1/4,  1/2,  1/2,  1,  1/2,  4,  4,  1/2, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>350271</td>\n",
       "      <td>[olive oil,  red onion,  diced tomatoes,  brow...</td>\n",
       "      <td>[1,  1,  1,  1 -2,  2]</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75597</th>\n",
       "      <td>267253</td>\n",
       "      <td>[tomatoes,  bacon,  elbow macaroni,  butter,  ...</td>\n",
       "      <td>[3,  4,  1,  3,  3,  1 1/2,  1/8,  2,  2 3/4]</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75598</th>\n",
       "      <td>170012</td>\n",
       "      <td>[olive oil,  garlic clove,  fresh spinach,  ch...</td>\n",
       "      <td>[1,  1/4,  1,  1,  8,  1,  1/2,  1,  3/4]</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75600</th>\n",
       "      <td>267827</td>\n",
       "      <td>[onion,  garlic cloves,  olive oil,  tomatoes,...</td>\n",
       "      <td>[1,  6,  2,  2,  1/2,  2,  1,  1/2,  1/4,  1, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75601</th>\n",
       "      <td>266983</td>\n",
       "      <td>[top round steak,  cornstarch,  ground ginger,...</td>\n",
       "      <td>[1/2,  1,  1/8,  1/8,  1,  1/2,  1]</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75602</th>\n",
       "      <td>253739</td>\n",
       "      <td>[cream of coconut,  water]</td>\n",
       "      <td>[1,  1,  1,  7 1/2,  1]</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RecipeId                                    IngredientParts  \\\n",
       "1        365718  [celery,  onion,  butter,  chicken broth,  lon...   \n",
       "2        141757  [Copycat Taco Bell Seasoned Beef,  yellow onio...   \n",
       "3        280351  [unsalted butter,  yellow onion,  carrots,  ga...   \n",
       "4        180505  [unflavored gelatin,  water,  sugar,  lemon,  ...   \n",
       "5        350271  [olive oil,  red onion,  diced tomatoes,  brow...   \n",
       "...         ...                                                ...   \n",
       "75597    267253  [tomatoes,  bacon,  elbow macaroni,  butter,  ...   \n",
       "75598    170012  [olive oil,  garlic clove,  fresh spinach,  ch...   \n",
       "75600    267827  [onion,  garlic cloves,  olive oil,  tomatoes,...   \n",
       "75601    266983  [top round steak,  cornstarch,  ground ginger,...   \n",
       "75602    253739                         [cream of coconut,  water]   \n",
       "\n",
       "                                    IngredientQuantities  \\\n",
       "1                          [1,  3/4,  6,  5,  2,  1,  2]   \n",
       "2      [3,  1/2,  1,  1,  3,  2,  1,  2 1/2,  2,  1, ...   \n",
       "3      [2,  1,  2,  2,  1,  1,  1/8,  1/4,  1,  4,  3...   \n",
       "4      [1,  1/4,  1/2,  1/2,  1,  1/2,  4,  4,  1/2, ...   \n",
       "5                                 [1,  1,  1,  1 -2,  2]   \n",
       "...                                                  ...   \n",
       "75597      [3,  4,  1,  3,  3,  1 1/2,  1/8,  2,  2 3/4]   \n",
       "75598          [1,  1/4,  1,  1,  8,  1,  1/2,  1,  3/4]   \n",
       "75600  [1,  6,  2,  2,  1/2,  2,  1,  1/2,  1/4,  1, ...   \n",
       "75601                [1/2,  1,  1/8,  1/8,  1,  1/2,  1]   \n",
       "75602                            [1,  1,  1,  7 1/2,  1]   \n",
       "\n",
       "       IngredientQuantitiesLen  IngredientPartsLen  \n",
       "1                            7                   9  \n",
       "2                           21                  19  \n",
       "3                           12                  13  \n",
       "4                           12                   8  \n",
       "5                            5                   4  \n",
       "...                        ...                 ...  \n",
       "75597                        9                  10  \n",
       "75598                        9                   8  \n",
       "75600                       19                  18  \n",
       "75601                        7                   6  \n",
       "75602                        5                   2  \n",
       "\n",
       "[56479 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate null values for Servings and Yield. \n",
    "# Too many null values\n",
    "recipes[\"RecipeServingsValue\"] = np.where(recipes[\"RecipeServings\"].isna(), 0, 1)\n",
    "recipes[\"RecipeYieldValue\"] = np.where(recipes[\"RecipeYield\"].isna(), 0, 1)\n",
    "print(recipes.groupby([\"RecipeServingsValue\", \"RecipeYieldValue\"])['RecipeId'].count())\n",
    "\n",
    "# investigate null values for ingredients\n",
    "# the maority contains both values - discard the ones that have null is an option\n",
    "# are we gonna use both columns?\n",
    "recipes[\"IngredientPartsEmpty\"] = recipes[\"IngredientParts\"].apply(lambda x: x == [])\n",
    "recipes[\"IngredientQuantitiesEmpty\"] = recipes[\"IngredientQuantities\"].apply(lambda x: x == [])\n",
    "print(recipes.groupby([\"IngredientPartsEmpty\", \"IngredientQuantitiesEmpty\"])['RecipeId'].count())\n",
    "#print(recipes.groupby([\"IngredientPartsValue\", \"RecipeServingsValue\"])['RecipeId'].count())\n",
    "\n",
    "                 \n",
    "# investigate amounts of ingredient parts that don't match the amount of ingredients\n",
    "# too many unmatching ingredient parts with quantities.. uff.\n",
    "recipes[\"IngredientPartsLen\"] = recipes[\"IngredientParts\"].apply(len)\n",
    "recipes[\"IngredientQuantitiesLen\"] = recipes[\"IngredientQuantities\"].apply(len)\n",
    "recipes[\"ingredientsDiff\"] = recipes[\"IngredientPartsLen\"] - recipes[\"IngredientQuantitiesLen\"]\n",
    "print(\"number of corrupted ingredient list\", len(recipes[recipes[\"ingredientsDiff\"] != 0]))\n",
    "recipes[recipes[\"ingredientsDiff\"] != 0][[\"RecipeId\", \"IngredientParts\", \"IngredientQuantities\", \"IngredientQuantitiesLen\", \"IngredientPartsLen\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.info()\n",
    "\n",
    "# To do: entender os valores nulos das colunas Rating, Lika e TestSetId e o que fazer com eles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.info()\n",
    "# no missing values: GOOD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do geral: entender o que a tabela tem de info, red flags que temos que tratar? mudar o datatype? fazer uns graficos para a gente ter mais noção dos dados (uns 2 ou 3 mais significativos)\n",
    "# To do: have a look at common statistics of the dataset (por exemplo df.describe() ou sns.boxplot(df);)\n",
    "# To do: check the balancing of classes/labels (por exemplo df.groupby(\"variety\").size())\n",
    "# To do: have a look at the feature distributions with a pairplot (exemplo sns.pairplot(df, hue=\"variety\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"});)\n",
    "### and look at class-dependent pairplots too (exemplo na celula seguinte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_class = df.groupby(by=\"variety\")\n",
    "\n",
    "df_setosa = df_grouped_by_class.get_group(\"Setosa\")\n",
    "df_versicolor = df_grouped_by_class.get_group(\"Versicolor\")\n",
    "df_virginica = df_grouped_by_class.get_group(\"Virginica\")\n",
    "\n",
    "class_labels = {\n",
    "    \"Setosa\" : {\n",
    "        \"color\" : \"blue\",\n",
    "        \"data\" : df_setosa\n",
    "    },\n",
    "    \"Versicolor\" : {\n",
    "        \"color\" : \"green\",\n",
    "        \"data\" : df_versicolor\n",
    "    },\n",
    "    \"Virginica\" : {\n",
    "        \"color\" : \"red\",\n",
    "        \"data\" : df_virginica\n",
    "    }\n",
    "}\n",
    "\n",
    "for class_i in class_labels:\n",
    "    class_color = class_labels[class_i][\"color\"]\n",
    "    class_df = class_labels[class_i][\"data\"]\n",
    "    p = sns.pairplot(class_df, diag_kind=\"hist\", diag_kws={\"color\" : class_color}, plot_kws={\"color\" : class_color, \"label\" : class_i})\n",
    "    p.fig.suptitle(class_i, y=1.0, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also leverage the dataprep package to get a nice summary report\n",
    "report = sv.analyze(df)\n",
    "report.show_notebook()\n",
    "\n",
    "# We can also leverage the yadata_profiling package to get a nice summary report\n",
    "profile = ProfileReport(df, title=\"Iris Data - Summary Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Data Preparation\n",
    "\n",
    "The goal is assure data quality: includes removing wrong/corrupt \n",
    "data entries and making sure the entries are standardized, e.g. enforcing certain encodings. \n",
    "Then transforms the data in order to make it suitable for the modelling step. This includes scaling, dimensionality\n",
    "reduction, data augmentation, outlier removal, etc.\\\n",
    " \\\n",
    "In practise, this will rarely be the case. On average, this step takes up to **80%** of \n",
    "the time of the whole project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: transform categorical feature into categorical variables (exemplo df[\"variety\"] = df[\"variety\"].astype(\"category\"))\n",
    "# fill/remove/change missing/corrupt values\n",
    "# optionally save the cleaned datasets for versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: ver se precisamos standardize alguma feature (exemplo na celula seguinte com o StandardScaler), se precisamos imputar valores em registros com valores nulos, \n",
    "# se precisamos lidar com outliers, se precisamos usar alguma estretégia de redução de dimensionalidade (tipo PCA na próxima celula)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# dimensionality reduction\n",
    "transform_pca = PCA()\n",
    "\n",
    "# value imputing\n",
    "\n",
    "# outlier detection/removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data set into *train* and *test* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: ver se vamos usar um split para validação, ou usar cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(df.iloc[:, :-1], df.iloc[:, -1:],\n",
    "                   test_size=0.3, \n",
    "                   shuffle=True,\n",
    "                   random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4: Modeling\n",
    "\n",
    "In this phase, the model is trained and tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: escolher quais classifiers vamos testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, you want to find the best classifier. As candidates, consider\n",
    "#   1. LogisticRegression\n",
    "#   2. RandomForestClassifier\n",
    "#   3. other algorithms from sklearn (easy to add)\n",
    "#   4. custom algorithms (more difficult to implement)\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# train the models\n",
    "pipeline = Pipeline(steps=[(\"scaler\", transform_scaler), \n",
    "                           (\"pca\", transform_pca),\n",
    "                           (\"model\", None)])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "  \"pca__n_components\" : [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "  \"model\" : [model_logistic_regression],\n",
    "  \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "  \"model\" : [model_gradient_boosting],\n",
    "  \"model__n_estimators\" : [10, 20, 30]\n",
    "}\n",
    "\n",
    "parameter_grid_random_forest = {\n",
    "  \"model\" : [model_random_forest],\n",
    "  \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "  \"model__max_depth\" : [2, 3, 4],\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "                       parameter_grid_random_forest,\n",
    "                       parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid, \n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2, \n",
    "                      cv=5,  # number of folds for cross-validation \n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# here, the actual training and grid search happens\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluation\n",
    "\n",
    "Once the appropriate models are chosen, they are evaluated on the test set. For\n",
    "this, different evaluation metrics can be used. Furthermore, this step is where\n",
    "the models and their predictions are analyzed resp. different properties, including\n",
    "feature importance, robustness to outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_test, y_test.values.ravel()))\n",
    "\n",
    "# contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_test), y_test.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional, if you're curious) \n",
    "# for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretability\n",
    "\n",
    "##### Disclaimer: This only works if shap is installed.\n",
    "\n",
    "In addition to models and their predictions, it is often important to understand _why_ a model makes certain predictions. \n",
    "There is a lot of literature on how this can be achieved (explainability), but we will only show the use of Shapley values\n",
    "using the python module \"shap\", which is a combination of Shapley values and LIME. \n",
    "You can find more information on this topic [here](https://christophm.github.io/interpretable-ml-book/shap.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume random forest model\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# compute shapley values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "expected_value = explainer.expected_value\n",
    "print(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dependent plots of shapley values for each feature\n",
    "for i,c in enumerate(df.variety.unique()):\n",
    "    shap.summary_plot(shap_values[i], X_train, show=False)\n",
    "    plt.title(\"Shapley values for \"+str(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the computed SHAP values, we can interpret that the *petal.width* has a positive impact on the output of the model \n",
    "if the feature value is moderate. For high aand low values, the impact is negative. The same observation\n",
    "holds for *petal.length*. Besides, the impact of the *sepal.length* and *sepal.width* features are rather low. By impact on a \n",
    "the target, we model the probability that we classify that target. Thus, if *petal.width* is high, it is more likely\n",
    "that we classify the data point as Versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deployment\n",
    "\n",
    "Now that you have chosen and trained your model, it is time to deploy it to your\n",
    "clients system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_service_classify_iris(datapoint):\n",
    "    \n",
    "  # make sure the provided datapoints adhere to the correct format for model input\n",
    "\n",
    "  # fetch your trained model\n",
    "  model = search.best_estimator_\n",
    "\n",
    "  # make prediction with the model\n",
    "  prediction = model.predict(datapoint)\n",
    "\n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Analytics Cup, you need to export your prediction in a very specific output format. This is a csv file without an index and two columns, *id* and *prediction*. Note that the values in both columns need to be integer values, and especially in the *prediction* column either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: arrumar a celula abaixo com os nossos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "output = pd.DataFrame(df_flowers.variety)\n",
    "output['id'] = df_flowers.index\n",
    "output = output.rename(columns={'variety': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "output.to_csv('analzticscuppredictionfile.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
