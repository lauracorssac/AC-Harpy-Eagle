{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Disclaimer: We use some advanced packages here without detailed explanation. You can use these, but we do not provide any support.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install them, you can uncomment the following lines:\n",
    "# (%pip will call pip from the currently active python environment)\n",
    "# %pip install scikit-learn\n",
    "\n",
    "# Note: Some of these packages are still not compatible with Python 3.12 yet\n",
    "# %pip install sweetviz\n",
    "# %pip install ydata_profiling\n",
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "#import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility \n",
    "\n",
    "A best practice in data analytics projects is to work with *seeds* to ensure the reproducability of results. \n",
    "This is especially important in the Analytics Cup, since the rules require you to write a self-contained\n",
    "script that produces reproducable results. \n",
    "\n",
    "To achieve this, we can set seeds for all used random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Business Understanding\n",
    "\n",
    "Serves to assess use cases, feasibility, requirements, and\n",
    "risks of the endeavored data driven project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Startup that suggests new recipes to users\\\n",
    "But we have been having many cancelations of subscriptions\\\n",
    "Problem was that the users found that the recipes suggested (even though they had high quality) did not match the customer's diet and needs\\\n",
    "Now we have a system of likes and dislikes for the recipes and a new user interface, where the users can enter information about what they want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Data Understanding\n",
    "\n",
    "Assess the data quality and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_18412\\1456728697.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.read_csv(\"reviews.csv\")\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "diet = pd.read_csv(\"diet.csv\")\n",
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "requests = pd.read_csv(\"requests.csv\")\n",
    "reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the data and its attributes \\\n",
    "check if columns are properly named \\\n",
    "general overview over data, check for missing values, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diet pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet[\"Diet\"] = diet[\"Diet\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipes pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Name</th>\n",
       "      <th>CookTime</th>\n",
       "      <th>PrepTime</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>RecipeIngredientQuantities</th>\n",
       "      <th>RecipeIngredientParts</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>RecipeYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Bow Ties With Broccoli Pesto</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>[6,  2,  1 1/2,  1/4,  1/2,  4,  1 1/2,  1 1/2...</td>\n",
       "      <td>[hazelnuts,  broccoli florets,  fresh parsley ...</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Cashew-chutney Rice</td>\n",
       "      <td>3600</td>\n",
       "      <td>600</td>\n",
       "      <td>Other</td>\n",
       "      <td>[1,  3/4,  6,  5,  2,  1,  2]</td>\n",
       "      <td>[celery,  onion,  butter,  chicken broth,  lon...</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Copycat Taco Bell Nacho Fries BellGrande</td>\n",
       "      <td>3600</td>\n",
       "      <td>2700</td>\n",
       "      <td>Other</td>\n",
       "      <td>[3,  1/2,  1,  1,  3,  2,  1,  2 1/2,  2,  1, ...</td>\n",
       "      <td>[Copycat Taco Bell Seasoned Beef,  yellow onio...</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Slow Cooker Jalapeno Cheddar Cheese Soup</td>\n",
       "      <td>18000</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>[2,  1,  2,  2,  1,  1,  1/8,  1/4,  1,  4,  3...</td>\n",
       "      <td>[unsalted butter,  yellow onion,  carrots,  ga...</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Cool &amp; Crisp Citrus Chiffon Pie</td>\n",
       "      <td>3600</td>\n",
       "      <td>1800</td>\n",
       "      <td>Other</td>\n",
       "      <td>[1,  1/4,  1/2,  1/2,  1,  1/2,  4,  4,  1/2, ...</td>\n",
       "      <td>[unflavored gelatin,  water,  sugar,  lemon,  ...</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId                                      Name  CookTime  PrepTime  \\\n",
       "0     73440              Bow Ties With Broccoli Pesto         0      1800   \n",
       "1    365718                       Cashew-chutney Rice      3600       600   \n",
       "2    141757  Copycat Taco Bell Nacho Fries BellGrande      3600      2700   \n",
       "3    280351  Slow Cooker Jalapeno Cheddar Cheese Soup     18000      1800   \n",
       "4    180505           Cool & Crisp Citrus Chiffon Pie      3600      1800   \n",
       "\n",
       "  RecipeCategory                         RecipeIngredientQuantities  \\\n",
       "0          Other  [6,  2,  1 1/2,  1/4,  1/2,  4,  1 1/2,  1 1/2...   \n",
       "1          Other                      [1,  3/4,  6,  5,  2,  1,  2]   \n",
       "2          Other  [3,  1/2,  1,  1,  3,  2,  1,  2 1/2,  2,  1, ...   \n",
       "3          Other  [2,  1,  2,  2,  1,  1,  1/8,  1/4,  1,  4,  3...   \n",
       "4          Other  [1,  1/4,  1/2,  1/2,  1,  1/2,  4,  4,  1/2, ...   \n",
       "\n",
       "                               RecipeIngredientParts  Calories  FatContent  \\\n",
       "0  [hazelnuts,  broccoli florets,  fresh parsley ...     241.3        10.1   \n",
       "1  [celery,  onion,  butter,  chicken broth,  lon...     370.8        17.5   \n",
       "2  [Copycat Taco Bell Seasoned Beef,  yellow onio...     377.6        20.9   \n",
       "3  [unsalted butter,  yellow onion,  carrots,  ga...     282.8        16.5   \n",
       "4  [unflavored gelatin,  water,  sugar,  lemon,  ...     257.5         8.6   \n",
       "\n",
       "   SaturatedFatContent  CholesterolContent  SodiumContent  \\\n",
       "0                  1.2                 0.0           13.1   \n",
       "1                  7.2                22.9          553.3   \n",
       "2                 10.5                45.7         1501.8   \n",
       "3                 10.3                50.5          630.2   \n",
       "4                  2.4               110.7          160.9   \n",
       "\n",
       "   CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n",
       "0                 31.8           2.3           1.4             6.7   \n",
       "1                 44.3           1.6           2.2             9.4   \n",
       "2                 36.6           3.8           6.1            12.9   \n",
       "3                 22.8           2.3           2.7            11.7   \n",
       "4                 39.8           0.4          30.2             6.3   \n",
       "\n",
       "   RecipeServings RecipeYield  \n",
       "0             9.0         NaN  \n",
       "1             8.0         NaN  \n",
       "2             8.0         NaN  \n",
       "3             6.0         NaN  \n",
       "4             6.0         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change types of column\n",
    "def refactorIngredients(ingredients):\n",
    "    if ingredients == \"character(0)\":\n",
    "        return []\n",
    "    ingredients = ingredients.replace(\"\\\\\", '').replace(\"\\\"\", '').replace('c(','').replace(')', '')\n",
    "    ingredients = ingredients.split(\",\")\n",
    "    return ingredients\n",
    "\n",
    "recipes[\"RecipeIngredientQuantities\"] = recipes[\"RecipeIngredientQuantities\"].apply(lambda x: refactorIngredients(x))\n",
    "recipes[\"RecipeIngredientParts\"] = recipes[\"RecipeIngredientParts\"].apply(lambda x: refactorIngredients(x))\n",
    "\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75604 entries, 0 to 75603\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   RecipeId                    75604 non-null  int64  \n",
      " 1   Name                        75604 non-null  object \n",
      " 2   CookTime                    75604 non-null  int64  \n",
      " 3   PrepTime                    75604 non-null  int64  \n",
      " 4   RecipeCategory              75604 non-null  object \n",
      " 5   RecipeIngredientQuantities  75604 non-null  object \n",
      " 6   RecipeIngredientParts       75604 non-null  object \n",
      " 7   Calories                    75604 non-null  float64\n",
      " 8   FatContent                  75604 non-null  float64\n",
      " 9   SaturatedFatContent         75604 non-null  float64\n",
      " 10  CholesterolContent          75604 non-null  float64\n",
      " 11  SodiumContent               75604 non-null  float64\n",
      " 12  CarbohydrateContent         75604 non-null  float64\n",
      " 13  FiberContent                75604 non-null  float64\n",
      " 14  SugarContent                75604 non-null  float64\n",
      " 15  ProteinContent              75604 non-null  float64\n",
      " 16  RecipeServings              48891 non-null  float64\n",
      " 17  RecipeYield                 25309 non-null  object \n",
      "dtypes: float64(10), int64(3), object(5)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "recipes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Name</th>\n",
       "      <th>CookTime</th>\n",
       "      <th>PrepTime</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeDiet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Bow Ties With Broccoli Pesto</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Cashew-chutney Rice</td>\n",
       "      <td>3600</td>\n",
       "      <td>600</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Copycat Taco Bell Nacho Fries BellGrande</td>\n",
       "      <td>3600</td>\n",
       "      <td>2700</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Slow Cooker Jalapeno Cheddar Cheese Soup</td>\n",
       "      <td>18000</td>\n",
       "      <td>1800</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Cool &amp; Crisp Citrus Chiffon Pie</td>\n",
       "      <td>3600</td>\n",
       "      <td>1800</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75599</th>\n",
       "      <td>253577</td>\n",
       "      <td>Frijoles Negros- Crock Pot Mexican Black Beans</td>\n",
       "      <td>43200</td>\n",
       "      <td>28800</td>\n",
       "      <td>121.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1175.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75600</th>\n",
       "      <td>267827</td>\n",
       "      <td>Moose Moussaka</td>\n",
       "      <td>3600</td>\n",
       "      <td>2700</td>\n",
       "      <td>652.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>197.9</td>\n",
       "      <td>435.5</td>\n",
       "      <td>51.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>50.1</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75601</th>\n",
       "      <td>266983</td>\n",
       "      <td>Cantonese Pepper Steak for Two (Or More)</td>\n",
       "      <td>1800</td>\n",
       "      <td>900</td>\n",
       "      <td>223.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>78.3</td>\n",
       "      <td>725.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75602</th>\n",
       "      <td>253739</td>\n",
       "      <td>Coconut Cream Cooler</td>\n",
       "      <td>300</td>\n",
       "      <td>120</td>\n",
       "      <td>2229.8</td>\n",
       "      <td>80.3</td>\n",
       "      <td>69.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.7</td>\n",
       "      <td>369.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>317.9</td>\n",
       "      <td>26.7</td>\n",
       "      <td>Vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75603</th>\n",
       "      <td>78171</td>\n",
       "      <td>Cheater Risotto</td>\n",
       "      <td>960</td>\n",
       "      <td>600</td>\n",
       "      <td>654.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75604 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RecipeId                                            Name  CookTime  \\\n",
       "0         73440                    Bow Ties With Broccoli Pesto         0   \n",
       "1        365718                             Cashew-chutney Rice      3600   \n",
       "2        141757        Copycat Taco Bell Nacho Fries BellGrande      3600   \n",
       "3        280351        Slow Cooker Jalapeno Cheddar Cheese Soup     18000   \n",
       "4        180505                 Cool & Crisp Citrus Chiffon Pie      3600   \n",
       "...         ...                                             ...       ...   \n",
       "75599    253577  Frijoles Negros- Crock Pot Mexican Black Beans     43200   \n",
       "75600    267827                                  Moose Moussaka      3600   \n",
       "75601    266983        Cantonese Pepper Steak for Two (Or More)      1800   \n",
       "75602    253739                            Coconut Cream Cooler       300   \n",
       "75603     78171                                 Cheater Risotto       960   \n",
       "\n",
       "       PrepTime  Calories  FatContent  SaturatedFatContent  \\\n",
       "0          1800     241.3        10.1                  1.2   \n",
       "1           600     370.8        17.5                  7.2   \n",
       "2          2700     377.6        20.9                 10.5   \n",
       "3          1800     282.8        16.5                 10.3   \n",
       "4          1800     257.5         8.6                  2.4   \n",
       "...         ...       ...         ...                  ...   \n",
       "75599     28800     121.5         0.5                  0.1   \n",
       "75600      2700     652.2        25.8                 10.7   \n",
       "75601       900     223.9         9.2                  3.6   \n",
       "75602       120    2229.8        80.3                 69.3   \n",
       "75603       600     654.1        13.8                  6.9   \n",
       "\n",
       "       CholesterolContent  SodiumContent  CarbohydrateContent  FiberContent  \\\n",
       "0                     0.0           13.1                 31.8           2.3   \n",
       "1                    22.9          553.3                 44.3           1.6   \n",
       "2                    45.7         1501.8                 36.6           3.8   \n",
       "3                    50.5          630.2                 22.8           2.3   \n",
       "4                   110.7          160.9                 39.8           0.4   \n",
       "...                   ...            ...                  ...           ...   \n",
       "75599                 0.0         1175.1                 22.2           7.8   \n",
       "75600               197.9          435.5                 51.9           7.5   \n",
       "75601                78.3          725.9                  7.3           1.1   \n",
       "75602                 0.0          294.7                369.0          15.7   \n",
       "75603                34.6         1114.0                 92.2           3.9   \n",
       "\n",
       "       SugarContent  ProteinContent  RecipeDiet  \n",
       "0               1.4             6.7       Vegan  \n",
       "1               2.2             9.4    Omnivore  \n",
       "2               6.1            12.9    Omnivore  \n",
       "3               2.7            11.7    Omnivore  \n",
       "4              30.2             6.3  Vegetarian  \n",
       "...             ...             ...         ...  \n",
       "75599           0.6             7.9       Vegan  \n",
       "75600           7.2            50.1  Vegetarian  \n",
       "75601           1.7            26.7    Omnivore  \n",
       "75602         317.9            26.7       Vegan  \n",
       "75603           4.2            21.8    Omnivore  \n",
       "\n",
       "[75604 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determines if recipe is veggie, vegan or omnivore\n",
    "def categorizeRecipe(ingredients):\n",
    "    meat_derivates = [\"pork\", \"beef\", \"meat\", \"fish\", \"tuna\", \"chicken\", \"squid\", \"schrimp\", \"trout\", \"mussels\", \n",
    "                      \"fillet\", \"lamb\", \"scallops\", \"sardine\", \"salmon\", \"lobster\", \"steak\", \"bacon\", \"ham\", \"oyster\"]\n",
    "    animal_derivates = [\"milk\", \"egg\", \"honey\", \"gelatin\", \"butter\", \"mayonnaise\", \"cheese\", \"margarine\", \n",
    "                    \" heavy\", \"yogurt\", \"pudding\", \"shortening\", \"ice cream\", \"chocolate\", \"alfredo\", \"Miracle Whip\", \"half-and-half\"]\n",
    "    vegan_exclusions = [\"substitute\", \"peanut\", \"apple\", \"vegan\", \"soymilk\"]\n",
    "    vegan = True\n",
    "    for ingredient in ingredients:\n",
    "        if any(word in ingredient.lower() for word in meat_derivates):\n",
    "            return \"Omnivore\"\n",
    "        if ingredient in vegan_exclusions:\n",
    "            continue\n",
    "        if any(word in ingredient.lower() for word in animal_derivates):\n",
    "            vegan = False\n",
    "    if vegan: \n",
    "        return \"Vegan\"\n",
    "    else: \n",
    "        return \"Vegetarian\"\n",
    "\n",
    "recipes[\"RecipeDiet\"] = recipes[\"RecipeIngredientParts\"].apply(lambda x: categorizeRecipe(x))\n",
    "recipes['RecipeDiet'] = recipes['RecipeDiet'].astype('category')\n",
    "\n",
    "# Create another table \"recipe extra info\" columns category, ingredient quatities, parts\n",
    "selected_columns = ['RecipeCategory', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeServings', 'RecipeYield']\n",
    "recipe_extra_info = recipes[selected_columns]\n",
    "recipes = recipes.drop(columns=selected_columns)\n",
    "\n",
    "recipes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requests pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Time</th>\n",
       "      <th>HighCalories</th>\n",
       "      <th>HighProtein</th>\n",
       "      <th>LowFat</th>\n",
       "      <th>LowSugar</th>\n",
       "      <th>HighFiber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001012259B</td>\n",
       "      <td>73440</td>\n",
       "      <td>1799.950949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641B</td>\n",
       "      <td>365718</td>\n",
       "      <td>4201.820980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803340263D</td>\n",
       "      <td>141757</td>\n",
       "      <td>6299.861496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854048B</td>\n",
       "      <td>280351</td>\n",
       "      <td>19801.365796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2277685E</td>\n",
       "      <td>180505</td>\n",
       "      <td>5400.093457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId          Time  HighCalories  HighProtein  LowFat  \\\n",
       "0  2001012259B     73440   1799.950949           0.0  Indifferent       0   \n",
       "1      437641B    365718   4201.820980           0.0          Yes       0   \n",
       "2  1803340263D    141757   6299.861496           0.0  Indifferent       1   \n",
       "3      854048B    280351  19801.365796           0.0          Yes       1   \n",
       "4     2277685E    180505   5400.093457           0.0  Indifferent       0   \n",
       "\n",
       "      LowSugar  HighFiber  \n",
       "0            0          0  \n",
       "1  Indifferent          1  \n",
       "2  Indifferent          0  \n",
       "3            0          1  \n",
       "4            0          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   AuthorId      140195 non-null  object \n",
      " 1   RecipeId      140195 non-null  int64  \n",
      " 2   Time          140195 non-null  float64\n",
      " 3   HighCalories  140195 non-null  float64\n",
      " 4   HighProtein   140195 non-null  object \n",
      " 5   LowFat        140195 non-null  int64  \n",
      " 6   LowSugar      140195 non-null  object \n",
      " 7   HighFiber     140195 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "requests.info()\n",
    "# no missing values: GOOD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "requests = requests.rename(columns={\"HighCalories\": \"Calories\", \"HighProtein\":\"Protein\", \"LowFat\": \"Fat\", \"LowSugar\": \"Sugar\", \"HighFiber\":\"Fiber\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Time</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Fiber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001012259B</td>\n",
       "      <td>73440</td>\n",
       "      <td>1799.950949</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641B</td>\n",
       "      <td>365718</td>\n",
       "      <td>4201.820980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803340263D</td>\n",
       "      <td>141757</td>\n",
       "      <td>6299.861496</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854048B</td>\n",
       "      <td>280351</td>\n",
       "      <td>19801.365796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2277685E</td>\n",
       "      <td>180505</td>\n",
       "      <td>5400.093457</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140190</th>\n",
       "      <td>163793B</td>\n",
       "      <td>78171</td>\n",
       "      <td>1560.649725</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140191</th>\n",
       "      <td>33888B</td>\n",
       "      <td>333262</td>\n",
       "      <td>1502.011466</td>\n",
       "      <td>1</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140192</th>\n",
       "      <td>401942C</td>\n",
       "      <td>49200</td>\n",
       "      <td>5999.274269</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140193</th>\n",
       "      <td>346866B</td>\n",
       "      <td>214815</td>\n",
       "      <td>899.523513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140194</th>\n",
       "      <td>1786859E</td>\n",
       "      <td>117923</td>\n",
       "      <td>7199.637837</td>\n",
       "      <td>1</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140195 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AuthorId  RecipeId          Time Calories      Protein Fat  \\\n",
       "0       2001012259B     73440   1799.950949        0  Indifferent   1   \n",
       "1           437641B    365718   4201.820980        0            1   1   \n",
       "2       1803340263D    141757   6299.861496        0  Indifferent   0   \n",
       "3           854048B    280351  19801.365796        0            1   0   \n",
       "4          2277685E    180505   5400.093457        0  Indifferent   1   \n",
       "...             ...       ...           ...      ...          ...  ..   \n",
       "140190      163793B     78171   1560.649725        0  Indifferent   1   \n",
       "140191       33888B    333262   1502.011466        1  Indifferent   0   \n",
       "140192      401942C     49200   5999.274269        0  Indifferent   1   \n",
       "140193      346866B    214815    899.523513        0            1   0   \n",
       "140194     1786859E    117923   7199.637837        1  Indifferent   1   \n",
       "\n",
       "              Sugar Fiber  \n",
       "0                 1     0  \n",
       "1       Indifferent     1  \n",
       "2       Indifferent     0  \n",
       "3                 1     1  \n",
       "4                 1     0  \n",
       "...             ...   ...  \n",
       "140190            1     1  \n",
       "140191            1     0  \n",
       "140192            1     1  \n",
       "140193  Indifferent     1  \n",
       "140194            1     1  \n",
       "\n",
       "[140195 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardizing column Calorie to the same format\n",
    "requests[\"Calories\"] = requests[\"Calories\"].astype(\"int\")\n",
    "\n",
    "# standardizing column Protein Yes->1\n",
    "requests[\"Protein\"] = requests[\"Protein\"].replace(\"Yes\",\"1\")\n",
    "\n",
    "# changing 0 -> 1 in column Sugar \n",
    "requests[\"Sugar\"] = requests[\"Sugar\"].replace(\"0\",\"1\")\n",
    "\n",
    "# changing 0 -> 1 and 1 -> 0  column Fat\n",
    "#requests[\"Fat\"] = requests[\"Fat\"].replace({1 : 0, 0 : 1})\n",
    "requests[\"Fat\"] = 1 - requests[\"Fat\"]\n",
    "\n",
    "# transforming macronutrients columns -> categories \n",
    "requests[[\"Calories\", \"Protein\", \"Fiber\", \"Sugar\", \"Fat\"]] = requests[[\"Calories\", \"Protein\", \"Fiber\", \"Sugar\", \"Fat\"]].astype(\"category\")\n",
    "\n",
    "requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(columns = [\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_grouped_by_class = df.groupby(by=\"variety\")\\n\\ndf_setosa = df_grouped_by_class.get_group(\"Setosa\")\\ndf_versicolor = df_grouped_by_class.get_group(\"Versicolor\")\\ndf_virginica = df_grouped_by_class.get_group(\"Virginica\")\\n\\nclass_labels = {\\n    \"Setosa\" : {\\n        \"color\" : \"blue\",\\n        \"data\" : df_setosa\\n    },\\n    \"Versicolor\" : {\\n        \"color\" : \"green\",\\n        \"data\" : df_versicolor\\n    },\\n    \"Virginica\" : {\\n        \"color\" : \"red\",\\n        \"data\" : df_virginica\\n    }\\n}\\n\\nfor class_i in class_labels:\\n    class_color = class_labels[class_i][\"color\"]\\n    class_df = class_labels[class_i][\"data\"]\\n    p = sns.pairplot(class_df, diag_kind=\"hist\", diag_kws={\"color\" : class_color}, plot_kws={\"color\" : class_color, \"label\" : class_i})\\n    p.fig.suptitle(class_i, y=1.0, size=15)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_grouped_by_class = df.groupby(by=\"variety\")\n",
    "\n",
    "df_setosa = df_grouped_by_class.get_group(\"Setosa\")\n",
    "df_versicolor = df_grouped_by_class.get_group(\"Versicolor\")\n",
    "df_virginica = df_grouped_by_class.get_group(\"Virginica\")\n",
    "\n",
    "class_labels = {\n",
    "    \"Setosa\" : {\n",
    "        \"color\" : \"blue\",\n",
    "        \"data\" : df_setosa\n",
    "    },\n",
    "    \"Versicolor\" : {\n",
    "        \"color\" : \"green\",\n",
    "        \"data\" : df_versicolor\n",
    "    },\n",
    "    \"Virginica\" : {\n",
    "        \"color\" : \"red\",\n",
    "        \"data\" : df_virginica\n",
    "    }\n",
    "}\n",
    "\n",
    "for class_i in class_labels:\n",
    "    class_color = class_labels[class_i][\"color\"]\n",
    "    class_df = class_labels[class_i][\"data\"]\n",
    "    p = sns.pairplot(class_df, diag_kind=\"hist\", diag_kws={\"color\" : class_color}, plot_kws={\"color\" : class_color, \"label\" : class_i})\n",
    "    p.fig.suptitle(class_i, y=1.0, size=15)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# We can also leverage the dataprep package to get a nice summary report\\nreport = sv.analyze(df)\\nreport.show_notebook()\\n\\n# We can also leverage the yadata_profiling package to get a nice summary report\\nprofile = ProfileReport(df, title=\"Iris Data - Summary Report\")\\nprofile\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# We can also leverage the dataprep package to get a nice summary report\n",
    "report = sv.analyze(df)\n",
    "report.show_notebook()\n",
    "\n",
    "# We can also leverage the yadata_profiling package to get a nice summary report\n",
    "profile = ProfileReport(df, title=\"Iris Data - Summary Report\")\n",
    "profile\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Data Preparation\n",
    "\n",
    "The goal is assure data quality: includes removing wrong/corrupt \n",
    "data entries and making sure the entries are standardized, e.g. enforcing certain encodings. \n",
    "Then transforms the data in order to make it suitable for the modelling step. This includes scaling, dimensionality\n",
    "reduction, data augmentation, outlier removal, etc.\\\n",
    " \\\n",
    "In practise, this will rarely be the case. On average, this step takes up to **80%** of \n",
    "the time of the whole project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: transform categorical feature into categorical variables (exemplo df[\"variety\"] = df[\"variety\"].astype(\"category\"))\n",
    "# fill/remove/change missing/corrupt values\n",
    "\n",
    "# To do: ver se precisamos standardize alguma feature (exemplo na celula seguinte com o StandardScaler), se precisamos imputar valores em registros com valores nulos, \n",
    "# se precisamos lidar com outliers, se precisamos usar alguma estretégia de redução de dimensionalidade (tipo PCA na próxima celula)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join das 4 tabelas\n",
    "- há users na tabela \"diet\" que nao estao na tabela \"reviews\" -- Ok!\n",
    "- match perfeito de recipeid and authorid entre requests e reviews -- Otimo!\n",
    "- todas as receitas de \"recipes\" estao sendo mostradas para pelo menos um usuario -- Ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabelas: diet, requests, reviews, recipes\n",
    "dietrequestsmerged = diet.merge(requests, on = [\"AuthorId\"])\n",
    "dietrequestsreviewsmerged = dietrequestsmerged.merge(reviews, on = [\"AuthorId\", \"RecipeId\"])\n",
    "dietrequestsreviewsmerged = dietrequestsreviewsmerged.rename(columns={\"Calories\" : \"Requested_Calories\"})\n",
    "mergedtables = dietrequestsreviewsmerged.merge(recipes, on = [\"RecipeId\"])\n",
    "mergedtables = mergedtables.rename(columns={\"Calories\" : \"Recipe_Calories\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97381 entries, 0 to 140194\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   AuthorId             97381 non-null  object  \n",
      " 1   Diet                 97381 non-null  category\n",
      " 2   Age                  97381 non-null  int64   \n",
      " 3   RecipeId             97381 non-null  int64   \n",
      " 4   Time                 97381 non-null  float64 \n",
      " 5   Requested_Calories   97381 non-null  category\n",
      " 6   Protein              97381 non-null  category\n",
      " 7   Fat                  97381 non-null  category\n",
      " 8   Sugar                97381 non-null  category\n",
      " 9   Fiber                97381 non-null  category\n",
      " 10  Like                 97381 non-null  object  \n",
      " 11  TestSetId            0 non-null      float64 \n",
      " 12  Name                 97381 non-null  object  \n",
      " 13  CookTime             97381 non-null  int64   \n",
      " 14  PrepTime             97381 non-null  int64   \n",
      " 15  Recipe_Calories      97381 non-null  float64 \n",
      " 16  FatContent           97381 non-null  float64 \n",
      " 17  SaturatedFatContent  97381 non-null  float64 \n",
      " 18  CholesterolContent   97381 non-null  float64 \n",
      " 19  SodiumContent        97381 non-null  float64 \n",
      " 20  CarbohydrateContent  97381 non-null  float64 \n",
      " 21  FiberContent         97381 non-null  float64 \n",
      " 22  SugarContent         97381 non-null  float64 \n",
      " 23  ProteinContent       97381 non-null  float64 \n",
      " 24  RecipeDiet           97381 non-null  category\n",
      "dtypes: category(7), float64(11), int64(4), object(3)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "submissiondataset = mergedtables[mergedtables[\"Like\"].isna()] #com Null na coluna Like\n",
    "trainandtestdataset = mergedtables[mergedtables[\"Like\"].notna()] #sem Null na coluna Like\n",
    "\n",
    "trainandtestdataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data set into *train* and *test* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ver se vamos usar um split para validação, ou usar cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop columns that should not be considered\n",
    "# Drop Name because is string and Random Forest doesn't accept strings\n",
    "trainandtestdataset = trainandtestdataset.drop(columns=['AuthorId', 'RecipeId', 'TestSetId', 'Name'])\n",
    "\n",
    "# Drop categorical values and transform them into one column for each of possible categories\n",
    "# This also removes remaining string values\n",
    "# ATTENTION: Eu nao sei se essa parte eh necessaria para o Linear Regression. Acredito que sim, mas, se nao, reorganizamos o codigo de repente\n",
    "categorical_values = ['Diet', 'RecipeDiet', 'Requested_Calories', 'Protein', 'Fat', 'Sugar', 'Fiber']\n",
    "\n",
    "for column in categorical_values:\n",
    "    new_data = pd.get_dummies(trainandtestdataset[column], prefix=column)\n",
    "    trainandtestdataset = pd.concat([trainandtestdataset, new_data], axis=1)\n",
    "    \n",
    "trainandtestdataset = trainandtestdataset.drop(columns=categorical_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97381 entries, 0 to 140194\n",
      "Data columns (total 30 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Age                    97381 non-null  int64  \n",
      " 1   Time                   97381 non-null  float64\n",
      " 2   Like                   97381 non-null  object \n",
      " 3   CookTime               97381 non-null  int64  \n",
      " 4   PrepTime               97381 non-null  int64  \n",
      " 5   Recipe_Calories        97381 non-null  float64\n",
      " 6   FatContent             97381 non-null  float64\n",
      " 7   SaturatedFatContent    97381 non-null  float64\n",
      " 8   CholesterolContent     97381 non-null  float64\n",
      " 9   SodiumContent          97381 non-null  float64\n",
      " 10  CarbohydrateContent    97381 non-null  float64\n",
      " 11  FiberContent           97381 non-null  float64\n",
      " 12  SugarContent           97381 non-null  float64\n",
      " 13  ProteinContent         97381 non-null  float64\n",
      " 14  Diet_Omnivore          97381 non-null  bool   \n",
      " 15  Diet_Vegan             97381 non-null  bool   \n",
      " 16  Diet_Vegetarian        97381 non-null  bool   \n",
      " 17  RecipeDiet_Omnivore    97381 non-null  bool   \n",
      " 18  RecipeDiet_Vegan       97381 non-null  bool   \n",
      " 19  RecipeDiet_Vegetarian  97381 non-null  bool   \n",
      " 20  Requested_Calories_0   97381 non-null  bool   \n",
      " 21  Requested_Calories_1   97381 non-null  bool   \n",
      " 22  Protein_1              97381 non-null  bool   \n",
      " 23  Protein_Indifferent    97381 non-null  bool   \n",
      " 24  Fat_0                  97381 non-null  bool   \n",
      " 25  Fat_1                  97381 non-null  bool   \n",
      " 26  Sugar_1                97381 non-null  bool   \n",
      " 27  Sugar_Indifferent      97381 non-null  bool   \n",
      " 28  Fiber_0                97381 non-null  bool   \n",
      " 29  Fiber_1                97381 non-null  bool   \n",
      "dtypes: bool(16), float64(10), int64(3), object(1)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Separate train and test data and X and Y variables\n",
    "\n",
    "X_features = trainandtestdataset.drop(columns=\"Like\")\n",
    "Y_classes = trainandtestdataset[\"Like\"]\n",
    "Y_classes = Y_classes.astype('category')\n",
    "\n",
    "trainandtestdataset.info()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y_classes,\n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=seed) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X_train: 77.904 rows × 24 columns\n",
    "- Y_train: 77.904 rows\n",
    "- X_test: 19.477 rows × 24 columns\n",
    "- Y_test: 19.477 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4: Modeling\n",
    "\n",
    "In this phase, the model is trained and tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled  = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9017302459310982\n",
      "[[16554   381]\n",
      " [ 1533  1009]]\n",
      "sensitivity =  0.3969315499606609\n",
      "specificity =  0.9775022143489814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "true_negatives = confusion_matrix[0][0]\n",
    "false_negatives = confusion_matrix[1][0]\n",
    "false_positives = confusion_matrix[0][1]\n",
    "true_positives = confusion_matrix[1][1]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "print(\"sensitivity = \", sensitivity)\n",
    "print(\"specificity = \", specificity)\n",
    "\n",
    "# Too many False predictions\n",
    "\n",
    "# Possible ways to improve\n",
    "# Re add the recipe name in some way - parse the string and see if the title is vegetarian. \n",
    "# Group the cook time in discrete chunks?\n",
    "# Group the other nutritional facts columns of recipe in discrete chunks?\n",
    "# Group age in chunks ?\n",
    "# Drop some columns from recipe like sodium \n",
    "# Reduce dimensionality. I guess fat, saturated fat and cholesterol are correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train_scaled, Y_train)\n",
    "Y_pred = logistic_regression.predict(X_test_scaled)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#trying to adjust feature balance\n",
    "logistic_regression = LogisticRegression(max_iter= 1000, class_weight='balanced' )\n",
    "\n",
    "logistic_regression.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logistic_regression.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.135287775324742\n",
      "[[   97 16838]\n",
      " [    4  2538]]\n",
      "-sensitivity =  0.998426435877262\n",
      "-specificity =  0.005727782698553292\n",
      "-classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.01      0.01     16935\n",
      "         1.0       0.13      1.00      0.23      2542\n",
      "\n",
      "    accuracy                           0.14     19477\n",
      "   macro avg       0.55      0.50      0.12     19477\n",
      "weighted avg       0.85      0.14      0.04     19477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "true_negatives = confusion_matrix[0][0]\n",
    "false_negatives = confusion_matrix[1][0]\n",
    "false_positives = confusion_matrix[0][1]\n",
    "true_positives = confusion_matrix[1][1]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "print(\"-sensitivity = \", sensitivity)\n",
    "print(\"-specificity = \", specificity)\n",
    "\n",
    "print(\"-classification report\\n\" , classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model_gradient_boosting \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# train the models\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtransform_scaler\u001b[49m), \n\u001b[0;32m     20\u001b[0m                            (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform_pca),\n\u001b[0;32m     21\u001b[0m                            (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[0;32m     23\u001b[0m parameter_grid_preprocessing \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca__n_components\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m     25\u001b[0m }\n\u001b[0;32m     27\u001b[0m parameter_grid_logistic_regression \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     28\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m : [model_logistic_regression],\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__C\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m],  \u001b[38;5;66;03m# inverse regularization strength\u001b[39;00m\n\u001b[0;32m     30\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Here, you want to find the best classifier. As candidates, consider\n",
    "#   1. LogisticRegression\n",
    "#   2. RandomForestClassifier\n",
    "#   3. other algorithms from sklearn (easy to add)\n",
    "#   4. custom algorithms (more difficult to implement)\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# train the models\n",
    "pipeline = Pipeline(steps=[(\"scaler\", transform_scaler), \n",
    "                           (\"pca\", transform_pca),\n",
    "                           (\"model\", None)])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "  \"pca__n_components\" : [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "  \"model\" : [model_logistic_regression],\n",
    "  \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "  \"model\" : [model_gradient_boosting],\n",
    "  \"model__n_estimators\" : [10, 20, 30]\n",
    "}\n",
    "\n",
    "parameter_grid_random_forest = {\n",
    "  \"model\" : [model_random_forest],\n",
    "  \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "  \"model__max_depth\" : [2, 3, 4],\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "                       parameter_grid_random_forest,\n",
    "                       parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid, \n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2, \n",
    "                      cv=5,  # number of folds for cross-validation \n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# here, the actual training and grid search happens\n",
    "search.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluation\n",
    "\n",
    "Once the appropriate models are chosen, they are evaluated on the test set. For\n",
    "this, different evaluation metrics can be used. Furthermore, this step is where\n",
    "the models and their predictions are analyzed resp. different properties, including\n",
    "feature importance, robustness to outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_test, Y_test.values.ravel()))\n",
    "\n",
    "# contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_test), Y_test.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional, if you're curious) \n",
    "# for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretability\n",
    "\n",
    "##### Disclaimer: This only works if shap is installed.\n",
    "\n",
    "In addition to models and their predictions, it is often important to understand _why_ a model makes certain predictions. \n",
    "There is a lot of literature on how this can be achieved (explainability), but we will only show the use of Shapley values\n",
    "using the python module \"shap\", which is a combination of Shapley values and LIME. \n",
    "You can find more information on this topic [here](https://christophm.github.io/interpretable-ml-book/shap.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume random forest model\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "model.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# compute shapley values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "expected_value = explainer.expected_value\n",
    "print(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dependent plots of shapley values for each feature\n",
    "for i,c in enumerate(df.variety.unique()):\n",
    "    shap.summary_plot(shap_values[i], X_train, show=False)\n",
    "    plt.title(\"Shapley values for \"+str(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the computed SHAP values, we can interpret that the *petal.width* has a positive impact on the output of the model \n",
    "if the feature value is moderate. For high aand low values, the impact is negative. The same observation\n",
    "holds for *petal.length*. Besides, the impact of the *sepal.length* and *sepal.width* features are rather low. By impact on a \n",
    "the target, we model the probability that we classify that target. Thus, if *petal.width* is high, it is more likely\n",
    "that we classify the data point as Versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deployment\n",
    "\n",
    "Now that you have chosen and trained your model, it is time to deploy it to your\n",
    "clients system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_service_classify_iris(datapoint):\n",
    "    \n",
    "  # make sure the provided datapoints adhere to the correct format for model input\n",
    "\n",
    "  # fetch your trained model\n",
    "  model = search.best_estimator_\n",
    "\n",
    "  # make prediction with the model\n",
    "  prediction = model.predict(datapoint)\n",
    "\n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Analytics Cup, you need to export your prediction in a very specific output format. This is a csv file without an index and two columns, *id* and *prediction*. Note that the values in both columns need to be integer values, and especially in the *prediction* column either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: arrumar a celula abaixo com os nossos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "output = pd.DataFrame(df_flowers.variety)\n",
    "output['id'] = df_flowers.index\n",
    "output = output.rename(columns={'variety': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "output.to_csv('analzticscuppredictionfile.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
