{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Disclaimer: We use some advanced packages here without detailed explanation. You can use these, but we do not provide any support.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install them, you can uncomment the following lines:\n",
    "# (%pip will call pip from the currently active python environment)\n",
    "\n",
    "# Note: Some of these packages are still not compatible with Python 3.12 yet\n",
    "# %pip install sweetviz\n",
    "# %pip install ydata_profiling\n",
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "#import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility \n",
    "\n",
    "A best practice in data analytics projects is to work with *seeds* to ensure the reproducability of results. \n",
    "This is especially important in the Analytics Cup, since the rules require you to write a self-contained\n",
    "script that produces reproducable results. \n",
    "\n",
    "To achieve this, we can set seeds for all used random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Business Understanding\n",
    "\n",
    "Serves to assess use cases, feasibility, requirements, and\n",
    "risks of the endeavored data driven project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Startup that suggests new recipes to users\\\n",
    "But we have been having many cancelations of subscriptions\\\n",
    "Problem was that the users found that the recipes suggested (even though they had high quality) did not match the customer's diet and needs\\\n",
    "Now we have a system of likes and dislikes for the recipes and a new user interface, where the users can enter information about what they want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Data Understanding\n",
    "\n",
    "Assess the data quality and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "diet = pd.read_csv(\"diet.csv\")\n",
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "requests = pd.read_csv(\"requests.csv\")\n",
    "reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the data and its attributes \\\n",
    "check if columns are properly named \\\n",
    "general overview over data, check for missing values, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows dietary preferences (vegan, vegetarian, omnivore) and age for each user \\\n",
    "271.907 rows \\\n",
    "The 3 groups have almost the same distibution of Age (see boxplot) \\\n",
    "Tem menos veganos (+-50k) e vegetarianos (+-80k) que onívoros (+-145k) mas acho que isso já é bem significativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet[diet[\"Diet\"].isnull()]\n",
    "# ou deletamos esse usuario ou colocamos que ele é onivoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet.groupby(['Diet']).agg(Median = (\"Age\", 'median'),\n",
    "                           Mean = (\"Age\", 'mean'),\n",
    "                           StdDev = (\"Age\", 'std'),\n",
    "                           Count = (\"AuthorId\", \"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = diet, x = \"Age\", y = \"Diet\", width = .5)\n",
    "# veganos um pouquinho mais velhos, mas diferenca insignificante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sofia:\n",
    "# nao entendi a diferenca entre Recipe Servings e Recipe Yield\n",
    "\n",
    "# To do: lidar com as colunas RecipeIngredientQuantities e RecipeIngredientParts, provavelmente vamos ter que usar elas e o formato atual tá pessimo hahaha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.info()\n",
    "# To do: investigar os valores nulos nas colunas RecipeServings e RecipeYield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of a short survey after suggesting new recipes \\\n",
    "140.195 rows com varios valores numlos nas colunas Rating, Like e TestSetId\\\n",
    "Não entendi bem o que sei o Test Set... É um id que para na linha 42.814, acho que facil preencher os proximos só seguindo os numeros \\\n",
    "WTF???? Todos os Ratings são 2 (ver boxplot). Isso é util no fim das contas? Deletar essa coluna???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"RatingValue\"] = np.where(reviews[\"Rating\"].isna(), 0, 1)\n",
    "reviews[\"LikeValue\"] = np.where(reviews[\"Like\"].isna(), 0, 1)\n",
    "reviews.groupby([\"RatingValue\", \"LikeValue\"])['AuthorId'].count()\n",
    "#tem rating sem like, like sem rating e null nas duas\n",
    "#Rating sem like: se maior que 2,5 entao Like (?)\n",
    "#Like sem rating:\n",
    "#Sem os dois: deleta a linha, não tras nenhuma info util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = reviews, x = \"Like\", y = \"Rating\", width = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review and Diet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os users de Reviews estão na tabela Diet! \\\n",
    "Não conlui nada novo com esse pairplot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dietreviewsmerged = diet.merge(reviews, on = [\"AuthorId\"])\n",
    "dietreviewsmerged = dietreviewsmerged[['AuthorId', 'Diet', 'Age', 'Rating', 'Like']]\n",
    "sns.pairplot(dietreviewsmerged, hue = \"Diet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.info()\n",
    "# no missing values: GOOD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do geral: entender o que a tabela tem de info, red flags que temos que tratar? mudar o datatype? fazer uns graficos para a gente ter mais noção dos dados (uns 2 ou 3 mais significativos)\n",
    "# To do: have a look at common statistics of the dataset (por exemplo df.describe() ou sns.boxplot(df);)\n",
    "# To do: check the balancing of classes/labels (por exemplo df.groupby(\"variety\").size())\n",
    "# To do: have a look at the feature distributions with a pairplot (exemplo sns.pairplot(df, hue=\"variety\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"});)\n",
    "### and look at class-dependent pairplots too (exemplo na celula seguinte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_class = df.groupby(by=\"variety\")\n",
    "\n",
    "df_setosa = df_grouped_by_class.get_group(\"Setosa\")\n",
    "df_versicolor = df_grouped_by_class.get_group(\"Versicolor\")\n",
    "df_virginica = df_grouped_by_class.get_group(\"Virginica\")\n",
    "\n",
    "class_labels = {\n",
    "    \"Setosa\" : {\n",
    "        \"color\" : \"blue\",\n",
    "        \"data\" : df_setosa\n",
    "    },\n",
    "    \"Versicolor\" : {\n",
    "        \"color\" : \"green\",\n",
    "        \"data\" : df_versicolor\n",
    "    },\n",
    "    \"Virginica\" : {\n",
    "        \"color\" : \"red\",\n",
    "        \"data\" : df_virginica\n",
    "    }\n",
    "}\n",
    "\n",
    "for class_i in class_labels:\n",
    "    class_color = class_labels[class_i][\"color\"]\n",
    "    class_df = class_labels[class_i][\"data\"]\n",
    "    p = sns.pairplot(class_df, diag_kind=\"hist\", diag_kws={\"color\" : class_color}, plot_kws={\"color\" : class_color, \"label\" : class_i})\n",
    "    p.fig.suptitle(class_i, y=1.0, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also leverage the dataprep package to get a nice summary report\n",
    "report = sv.analyze(df)\n",
    "report.show_notebook()\n",
    "\n",
    "# We can also leverage the yadata_profiling package to get a nice summary report\n",
    "profile = ProfileReport(df, title=\"Iris Data - Summary Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Data Preparation\n",
    "\n",
    "The goal is assure data quality: includes removing wrong/corrupt \n",
    "data entries and making sure the entries are standardized, e.g. enforcing certain encodings. \n",
    "Then transforms the data in order to make it suitable for the modelling step. This includes scaling, dimensionality\n",
    "reduction, data augmentation, outlier removal, etc.\\\n",
    " \\\n",
    "In practise, this will rarely be the case. On average, this step takes up to **80%** of \n",
    "the time of the whole project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: transform categorical feature into categorical variables (exemplo df[\"variety\"] = df[\"variety\"].astype(\"category\"))\n",
    "# fill/remove/change missing/corrupt values\n",
    "# optionally save the cleaned datasets for versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: ver se precisamos standardize alguma feature (exemplo na celula seguinte com o StandardScaler), se precisamos imputar valores em registros com valores nulos, \n",
    "# se precisamos lidar com outliers, se precisamos usar alguma estretégia de redução de dimensionalidade (tipo PCA na próxima celula)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# dimensionality reduction\n",
    "transform_pca = PCA()\n",
    "\n",
    "# value imputing\n",
    "\n",
    "# outlier detection/removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data set into *train* and *test* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: ver se vamos usar um split para validação, ou usar cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(df.iloc[:, :-1], df.iloc[:, -1:],\n",
    "                   test_size=0.3, \n",
    "                   shuffle=True,\n",
    "                   random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4: Modeling\n",
    "\n",
    "In this phase, the model is trained and tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: escolher quais classifiers vamos testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, you want to find the best classifier. As candidates, consider\n",
    "#   1. LogisticRegression\n",
    "#   2. RandomForestClassifier\n",
    "#   3. other algorithms from sklearn (easy to add)\n",
    "#   4. custom algorithms (more difficult to implement)\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# train the models\n",
    "pipeline = Pipeline(steps=[(\"scaler\", transform_scaler), \n",
    "                           (\"pca\", transform_pca),\n",
    "                           (\"model\", None)])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "  \"pca__n_components\" : [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "  \"model\" : [model_logistic_regression],\n",
    "  \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "  \"model\" : [model_gradient_boosting],\n",
    "  \"model__n_estimators\" : [10, 20, 30]\n",
    "}\n",
    "\n",
    "parameter_grid_random_forest = {\n",
    "  \"model\" : [model_random_forest],\n",
    "  \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "  \"model__max_depth\" : [2, 3, 4],\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "                       parameter_grid_random_forest,\n",
    "                       parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid, \n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2, \n",
    "                      cv=5,  # number of folds for cross-validation \n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# here, the actual training and grid search happens\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluation\n",
    "\n",
    "Once the appropriate models are chosen, they are evaluated on the test set. For\n",
    "this, different evaluation metrics can be used. Furthermore, this step is where\n",
    "the models and their predictions are analyzed resp. different properties, including\n",
    "feature importance, robustness to outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_test, y_test.values.ravel()))\n",
    "\n",
    "# contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_test), y_test.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional, if you're curious) \n",
    "# for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretability\n",
    "\n",
    "##### Disclaimer: This only works if shap is installed.\n",
    "\n",
    "In addition to models and their predictions, it is often important to understand _why_ a model makes certain predictions. \n",
    "There is a lot of literature on how this can be achieved (explainability), but we will only show the use of Shapley values\n",
    "using the python module \"shap\", which is a combination of Shapley values and LIME. \n",
    "You can find more information on this topic [here](https://christophm.github.io/interpretable-ml-book/shap.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume random forest model\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# compute shapley values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "expected_value = explainer.expected_value\n",
    "print(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dependent plots of shapley values for each feature\n",
    "for i,c in enumerate(df.variety.unique()):\n",
    "    shap.summary_plot(shap_values[i], X_train, show=False)\n",
    "    plt.title(\"Shapley values for \"+str(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the computed SHAP values, we can interpret that the *petal.width* has a positive impact on the output of the model \n",
    "if the feature value is moderate. For high aand low values, the impact is negative. The same observation\n",
    "holds for *petal.length*. Besides, the impact of the *sepal.length* and *sepal.width* features are rather low. By impact on a \n",
    "the target, we model the probability that we classify that target. Thus, if *petal.width* is high, it is more likely\n",
    "that we classify the data point as Versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deployment\n",
    "\n",
    "Now that you have chosen and trained your model, it is time to deploy it to your\n",
    "clients system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_service_classify_iris(datapoint):\n",
    "    \n",
    "  # make sure the provided datapoints adhere to the correct format for model input\n",
    "\n",
    "  # fetch your trained model\n",
    "  model = search.best_estimator_\n",
    "\n",
    "  # make prediction with the model\n",
    "  prediction = model.predict(datapoint)\n",
    "\n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Analytics Cup, you need to export your prediction in a very specific output format. This is a csv file without an index and two columns, *id* and *prediction*. Note that the values in both columns need to be integer values, and especially in the *prediction* column either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: arrumar a celula abaixo com os nossos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "output = pd.DataFrame(df_flowers.variety)\n",
    "output['id'] = df_flowers.index\n",
    "output = output.rename(columns={'variety': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "output.to_csv('analzticscuppredictionfile.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
